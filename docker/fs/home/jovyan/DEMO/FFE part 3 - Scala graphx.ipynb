{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.locationtech.jts.geom._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.locationtech.geomesa.spark.jts._\n",
    "\n",
    "// import spark.implicits._\n",
    "// below hack\n",
    "val spark2: SparkSession = spark\n",
    "import spark2.implicits._\n",
    "spark.withJTS\n",
    "\n",
    "import org.apache.spark.graphx._\n",
    "// To make some of the examples work we will also need RDD\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edges = [id: int, near_id: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "37052"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val edges = spark2.read.load(\"ffe_edges.parquet\")\n",
    "edges.cache()\n",
    "edges.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edge_rdd = MapPartitionsRDD[422] at map at <console>:49\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Edge(1732,1701,null)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// vertices.rdd.first()\n",
    "val edge_rdd: RDD[Edge[Any]] = \n",
    "    edges.rdd.map(x => Edge(x.getInt(0), x.getInt(1), null))\n",
    "edge_rdd.first()                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertices = [_c0: int, TARGET_FID: int ... 15 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vertices = spark2.read.load(\"ffe_vertices.parquet\")\n",
    "vertices.cache()\n",
    "vertices.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vert_rdd = MapPartitionsRDD[423] at map at <console>:49\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0,(1,Houghton Bay,POLYGON ((1749551.504199982 5422104.252850056, 1749551.544950008 5422110.366449833, 1749556.703549862 5422110.332049847, 1749556.662749767 5422104.218400002, 1749551.504199982 5422104.252850056)),null))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// vertices.rdd.first()\n",
    "val vert_rdd: RDD[(VertexId, (Int, String, Any, Any))] = \n",
    "    vertices.rdd.map(x => (x.getInt(0), (x.getInt(1), x.getString(2), x.get(9), null)))\n",
    "vert_rdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph = org.apache.spark.graphx.impl.GraphImpl@189d4250\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@189d4250"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Build the initial Graph\n",
    "val graph = Graph(vert_rdd, edge_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "facts = MapPartitionsRDD[505] at map at <console>:48\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array(1 is the null of 845, 1 is the null of 850, 1 is the null of 851, 1 is the null of 852, 1 is the null of 853, 1 is the null of 854, 1 is the null of 855, 1 is the null of 856, 1 is the null of 857, 1 is the null of 1268, 1 is the null of 1269, 1 is the null of 1270, 1 is the null of 1279, 4 is the null of 744, 4 is the null of 745, 4 is the null of 746, 4 is the null of 747, 4 is the null of 755, 4 is the null of 756, 4 is the null of 757, 4 is the null of 758, 4 is the null of 759, 4 is the null of 763, 4 is the null of 764, 4 is the null of 765, 4 is the null of 767, 4 is the null of 769, 4 is the null of 771, 4 is the null of 776, 4 is the null of 777, 8 is the null of..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val facts: RDD[String] =\n",
    "  graph.triplets.map(triplet =>\n",
    "    triplet.srcAttr._1 + \" is the \" + triplet.attr + \" of \" + triplet.dstAttr._1)\n",
    "facts.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37052"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.numEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3558,19)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.inDegrees.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((3558,95), (1084,13), (3586,61), (3702,5), (3007,28), (667,3), (1053,3), (1894,21), (2493,22), (1325,30))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.triangleCount().vertices.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sourceId = 4\n",
       "initialGraph = org.apache.spark.graphx.impl.GraphImpl@47fbac06\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@47fbac06"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sourceId: VertexId = 4 // The ultimate source\n",
    "// Initialize the graph such that all vertices except the root have distance infinity.\n",
    "val initialGraph = graph.mapVertices((id, _) =>\n",
    "    if (id == sourceId) 0.0 else Double.PositiveInfinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialGraph.numVertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoMesa Spark  - Scala",
   "language": "scala",
   "name": "geomesa_spark__scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
